{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tensorflow to create dense neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have been exposing how the forward propagation works, but as you may have noticed designing the matrixes for every subject case we work with, is a real headache, besides that here we are not taking into account the gradient descent and backpropagation part of it. \n",
    "We are going to do that, with tensorflow low level library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/feature_columns\n",
    "\n",
    "https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/\n",
    "    \n",
    "https://datascience.stackexchange.com/questions/29863/difference-between-indicator-column-and-categorical-identity-column-in-tensorflo\n",
    "   \n",
    "https://stackoverflow.com/questions/46423156/what-is-this-feature-column-and-how-does-it-affect-the-training\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column\n",
    "\n",
    "\n",
    "http://adventuresinmachinelearning.com/python-tensorflow-tutorial/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is basically a language for doing complex operations on multidimensional array like objects, called tensors. With it, we are able to organize complex computations, that allow us to build in a low level library complex machine learning models, like for example neural networks.\n",
    "\n",
    "We know what vectors and matrixes are right? They are objects for information storage, that are comprised of one and two dimensions respectively. The tensor, is an object that essentially fulfills the same utility, but with the detail that is able to store as many dimensions of data, as needed,being able to maintain it's properties for calculus , while increasing the number of dimensions that we take in consideration when defining the values of the data. \n",
    "\n",
    "Dimensions are interesting, in the sense that the more we take in consideration, the bigger picture we take when considering the relationship between different events. mathematically speaking, would be the equivalent of knowing that x and y equal 2 and 4, vs knowing that they equal two and 4 when z equaled 8.Basically, we are having a bigger understanding of the world. This nature for mathematics are what tensor reflect, essentially being a multiway array of data. \n",
    "\n",
    "A one dimensional tensor would be a vector, a two dimensional vector would be seen as a matrix, a 3rd dimensional one would be seen as a cube , ( different categories of matrixes) , a 4d tensor would be a list of cubes (groups of categorized matrixes),  a 5th dimensional vector would be analyzing cubes withing two dimensions ( a matrix of cubes ) and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorimages/tensor.png\"   style=\"width: 600px;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned, tensorflow is a language that allows to organize calculations and computations for this objects, in an organized manner. That organization of operations are called graphs, think of them as a canvas that represent all the conections and operationsthat the different tensors will perform to each other and that ultimately, will represent our algorithm,our supervised learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different methods to do so: \n",
    "\n",
    "First, we impor the package using import tensorflow as tf , all the method we call will work thanks to us specifying that they come from this package. \n",
    "\n",
    "After that, we call the objects, by defining them  \n",
    "\n",
    "esentially: tf.constant() , tf.variable() and tf.placeholder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.constant()\n",
    "This will create a tensor which numerical values, are formed by constant,natural numbers.\n",
    " Creating a tensor like this is the same as specifying a storage unit of n dimensions, whos values\n",
    " remain the same through time as normal numbers\n",
    " \n",
    "Args:\n",
    "value: A constant value (or list) of output type dtype.\n",
    "\n",
    "dtype: The type of the elements of the resulting tensor.\n",
    "\n",
    "shape: Optional dimensions of resulting tensor.\n",
    "\n",
    "name: Optional name for the tensor.\n",
    "\n",
    "verify_shape: Boolean that enables verification of a shape of values.\n",
    "\n",
    "\n",
    "More details here. https://www.tensorflow.org/api_docs/python/tf/constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-1. -1. -1.]\n",
      " [-1. -1. -1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Constant 1-D Tensor populated with value list.\n",
    "constant_tensor1 = tf.constant([1, 2, 3, 4, 5, 6, 7]) \n",
    "\n",
    "# Constant 2-D tensor populated with scalar value -1.\n",
    "constant_tensor2 = tf.constant(-1.0, shape=[2, 3]) \n",
    "\n",
    "\n",
    "print(constant_tensor1)\n",
    "print(constant_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we created a vector and a matrix. Tensors in their own right formed by constant variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.variable()\n",
    "\n",
    "This on the other hand, creates a tensor also with numerical values, but this ones are \n",
    "recongized as ones that can have different values through different instances.\n",
    "\n",
    "The Variable() constructor requires an initial value for the variable, which can be a Tensor of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.\n",
    "\n",
    "Its main arguments are the initial value of the variable and a name, the initial value can be a tensor of any size. \n",
    "\n",
    "Details : https://www.tensorflow.org/api_docs/python/tf/Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=() dtype=int32, numpy=36>\n",
      "<tf.Variable 'w_matrix:0' shape=(2, 3) dtype=int64, numpy=\n",
      "array([[4, 5, 6],\n",
      "       [6, 8, 9]])>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a variable.\n",
    "w = tf.Variable(36, name='w') # this for example, will create a zero dimensional tensor, a scalar.\n",
    "\n",
    "w_matrix = tf.Variable(np.array([[4,5,6],[6,8,9]]) , name = 'w_matrix')# we create a tensor\n",
    "# matrix \n",
    "\n",
    "\n",
    "\n",
    "print(w)\n",
    "print(w_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The advantage the variable tensor offers, it's that we can apply methods to update it's value for example , the assign method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int64, numpy=\n",
       "array([[10, 11, 12],\n",
       "       [12, 14, 15]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.assign(w + 1)\n",
    "w_matrix.assign(w_matrix + 6)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder()\n",
    "\n",
    "This creates tensors formed by objects that are like variables, with the main difference that they don't own an initial value. Basically when creating them, we are declaring  as \"reserved\" a memory space that will be filled in the future, with values. The reason we do this is because sometimes, we create first our neural network architecture before loading the data to it. Or we have different criterias as how we want to initialize values ( for example, to avoid exploding and vanishing gradients) \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_4:0\", shape=(1024, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(1024, 1024)) # We declare the placeholder, no value\n",
    "#stored yet just on this command\n",
    "\n",
    "rand_array = np.random.rand(1024, 1024) # the vector containing the data we will put in the\n",
    "# placeholder, a random generated array\n",
    "\n",
    "print(x) # If we print this, nothing will be seen inside X , just a placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9240374  0.47898015 0.11209893 ... 0.28928065 0.27164865 0.3012986 ]\n",
      " [0.37938744 0.73697186 0.03840093 ... 0.6313227  0.20122004 0.06329225]\n",
      " [0.35414892 0.08874901 0.24399182 ... 0.06801349 0.57358205 0.8249495 ]\n",
      " ...\n",
      " [0.6798764  0.9643369  0.9761579  ... 0.06170417 0.7129313  0.3940755 ]\n",
      " [0.6961393  0.27441642 0.21745612 ... 0.3125642  0.21894976 0.7965268 ]\n",
      " [0.17955014 0.38402048 0.6208931  ... 0.29515657 0.8132611  0.93698454]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # We define a session, to start introducing the data \n",
    "    print(sess.run(x, feed_dict={x: rand_array})) # The method to introduce the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations \n",
    "\n",
    "So thats how we create tensors, cool, but how do we operate them? We utilize operation objects,graphs and sessions to do so.Basically,  they are just objects that represent the operation that ocurrs,this allows us to organize operations by name and interchange their sequential order, when building models. Some examples are this \n",
    "\n",
    "tf.math.add()\n",
    "tf.math.subtract()\n",
    "\n",
    "Now, basically operations require not only for us to store the object, but also, to create a session to execute it. The reason for this is because that way we can work on the model design without having to worry on consumed ram. \n",
    "\n",
    "Also, sessions, as a good practice, are thougth to be closed after executing the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_1:0\", shape=(2, 3), dtype=float32)\n",
      "Tensor(\"Sub_1:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "constant_tensor2 = tf.constant(-1.0, shape=[2, 3]) \n",
    "\n",
    "constant_tensor3 = tf.constant(3.0, shape=[2, 3]) \n",
    "\n",
    "a = tf.math.add(constant_tensor2,constant_tensor3, name = None) # define tensor operation\n",
    "b = tf.math.subtract(constant_tensor2,constant_tensor3, name = None) # define tensor operation\n",
    "\n",
    "# If we call them, we see that we will only have the object. \n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the result, we need to create a session object, and run the operation as an instance of said session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2.],\n",
       "       [2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathexamples = tf.Session() # We define session object\n",
    "mathexamples.run(a) # We run the operation object, inside the session object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4., -4., -4.],\n",
       "       [-4., -4., -4.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathexamples.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x7f57084b12e8>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathexamples.close  # We close the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, operations are thought to be done in sequential order, allowing us to organize many complex procedures with these system. There is another advantage to working with them in this manner, and that is the graphs. A computational graph is a series of TensorFlow operations arranged in a sequential manner. Think of it like the mental map you have in mind when designing the architecture of the model or series of operations that you are creating, only that now, it is not only mental. The graph basically classifies the objects inside the code you write, in  into two objects.tf.Operation (or \"ops\") and  tf.Tensor and draws them in a diagram. \n",
    "\n",
    "Basically, if until now you understood sequences of operations organized from directly the code, now you can understand them drawn in a diagram, tensorflow will gather the operations and tensors produced in your session , that you declared as code, and draw it in a diagram. In that diagram, the operations will be presented as nodes, and the tensors as the edges of the graph. Lets see an example. \n",
    "\n",
    "Lets call again some tensors and operate on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_2:0\", shape=(2, 3), dtype=float32)\n",
      "Tensor(\"Sub_2:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "constant_tensor2 = tf.constant(-1.0, shape=[2, 3]) \n",
    "\n",
    "constant_tensor3 = tf.constant(3.0, shape=[2, 3]) \n",
    "\n",
    "constant_tensor5 = tf.constant(10.0, shape=[2, 3]) \n",
    "\n",
    "a = tf.math.add(constant_tensor2,constant_tensor3, name = None) # define tensor operation\n",
    "b = tf.math.subtract(constant_tensor2,constant_tensor3, name = None)\n",
    "\n",
    "c = tf.math.add(a,constant_tensor5, name = None)# define tensor operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12., 12., 12.],\n",
       "       [12., 12., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathegraphxamples = tf.Session() # We define session object and run operations\n",
    "mathegraphxamples.run(a)\n",
    "mathegraphxamples.run(b)\n",
    "mathegraphxamples.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7f571ddb2d30>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook # We  prepare our jupyter notebook to load the tensorboard\n",
    "tf.summary.FileWriter('./examplegraph',mathegraphxamples.graph) # we create our graph , \n",
    "# summarizing our sessions operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f571ddb2128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./examplegraph  # call our graph for seeing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathegraphxamples.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an actual neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know the basics now, essentially, this is what tensorflow is all about in a low level, \n",
    "it will from here get as harder as the models you try to train inside of them. To end this \n",
    "Wonderfull tutorial, let's see how a neural network is trained inside of here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('/home/nacho/Descargas/datasets/heart-disease-uci/heart.csv' \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets shuffle it in a training and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis = 1)\n",
    "\n",
    "Y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = shuffle (X, Y, random_state = 0)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate we want for our gradient descent, and the number of epochs\n",
    "# We want to use to train our data\n",
    "\n",
    "learning_rate = 0.2\n",
    "training_epochs = 100 \n",
    "\n",
    "# The number of layers we want, with the number of neurons we want them \n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "# Define cost function and training algorithm \n",
    "\n",
    "costf = 'cross entropy'\n",
    "traininga = \"gradient descent optimizer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the objects that will be placed inside the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the inputs as placeholder, we shall fill them when we execute our code\n",
    "n_dim = X.shape[1] # This will help define the vectors and matrices for calculation correctly\n",
    "n_class = 1 # The number  of categorie values possibles for Y \n",
    "\n",
    "\n",
    "\n",
    "#We need to solve the nlen thing \n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32)   # Specifying where we are going to put the vectors \n",
    "y_ = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# We define out weights and bias as variables also\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the weights as code,  we use the different input and each layers neurons as the dimensions\n",
    "# of the tensors we are creating  \n",
    "# We use truncated_normal to generate random values that are normal but also truncated, because we \n",
    "# want to use a sigmoid function, and thus avoid oversaturation.  We can use tf.random_normal when using a \n",
    "# relu function as activation \n",
    "\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bias for each layers\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model \n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    " \n",
    "    # Hidden layer with RELU activationsd\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1']) # We first multiply, and then add bias\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    " \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.sigmoid(layer_4)\n",
    " \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Calling model\n",
    "y = multilayer_perceptron(x, weights, biases) # Basically, this will execute all our layers computations, resulting\n",
    "# in a tensor y with our predicted results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function and training step \n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_)) #  Calculates the cross_entropy \n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function) # Executes the gradient descent optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define extra variables and functions of interest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to create lists, that will allow us to plot the evolution of the epochs accuracy and error after traini\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "cost_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define an operation that will initialize variables inside the graph. This is always necesary if we\n",
    "# called tensor variables \n",
    "init = tf.global_variables_initializer()  \n",
    "\n",
    "# The session object we are going to need for execution \n",
    "sess = tf.Session()\n",
    "sess.run(init)  # We initialize the global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: using values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict = {x: train_x.values, y_: train_y.values})  # We start with the training\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x.values, y_: train_y.values}) #We calculate the loss for that epoch\n",
    "    cost_history = np.append(cost_history, cost) # With that loss calculted we append it to a list\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))  # We calculate what would be the correct prediction\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # We define a function to calculate accuracy \n",
    "    pred_y = sess.run(y, feed_dict = {x: test_x.values}) # Predict after training in the epoch\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y.values)) # define a function to Calculate the error of that epoch\n",
    "    mse_ = sess.run(mse)  # we run said function\n",
    "    mse_history.append(mse_)  # We append the result to a list\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use accuracy, we get error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected dimension in the range [-1, 1), but got 1\n\t [[node ArgMax_1561 (defined at <ipython-input-176-fc9234678b87>:5) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node ArgMax_1561:\n Placeholder_19 (defined at <ipython-input-166-844432d3b8cf>:11)\n\nOriginal stack trace for 'ArgMax_1561':\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-176-fc9234678b87>\", line 5, in <module>\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))  # We calculate what would be the correct prediction\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 137, in argmax\n    return argmax_v2(input, axis, output_type, name)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 166, in argmax_v2\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 938, in arg_max\n    name=name)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 800, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3479, in create_op\n    op_def=op_def)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1961, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1320\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [-1, 1), but got 1\n\t [[{{node ArgMax_1561}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-fc9234678b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we run said function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmse_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# We append the result to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Execute the accuracy function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maccuracy_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 930\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    931\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1153\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1329\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [-1, 1), but got 1\n\t [[node ArgMax_1561 (defined at <ipython-input-176-fc9234678b87>:5) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node ArgMax_1561:\n Placeholder_19 (defined at <ipython-input-166-844432d3b8cf>:11)\n\nOriginal stack trace for 'ArgMax_1561':\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-176-fc9234678b87>\", line 5, in <module>\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))  # We calculate what would be the correct prediction\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 137, in argmax\n    return argmax_v2(input, axis, output_type, name)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 166, in argmax_v2\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 938, in arg_max\n    name=name)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 800, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3479, in create_op\n    op_def=op_def)\n  File \"/home/nacho/anaconda3/envs/deepl1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1961, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict = {x: train_x.values, y_: train_y.values})  # We start with the training\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x.values, y_: train_y.values}) #We calculate the loss for that epoch\n",
    "    cost_history = np.append(cost_history, cost) # With that loss calculted we append it to a list\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))  # We calculate what would be the correct prediction\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # We define a function to calculate accuracy \n",
    "    pred_y = sess.run(y, feed_dict = {x: test_x.values}) # Predict after training in the epoch\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y.values)) # define a function to Calculate the error of that epoch\n",
    "    mse_ = sess.run(mse)  # we run said function\n",
    "    mse_history.append(mse_)  # We append the result to a list\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x.values, y_: train_y.values})) # Execute the accuracy function\n",
    "    accuracy_history.append(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-91216a39c8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We define a function to calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Predict after training in the epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# define a function to Calculate the error of that epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we run said function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmse_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# We append the result to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return construct_result(left, result,\n\u001b[0;32m-> 1585\u001b[0;31m                                 index=left.index, name=res_name, dtype=None)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(left, result, index, name, dtype)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0menough\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mstill\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \"\"\"\n\u001b[0;32m-> 1474\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 262\u001b[0;31m                                       raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl1/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict = {x: train_x, y_: train_y})  # We start with the training\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y}) #We calculate the loss for that epoch\n",
    "    cost_history = np.append(cost_history, cost) # With that loss calculted we append it to a list\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))  # We calculate what would be the correct prediction\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # We define a function to calculate accuracy \n",
    "    pred_y = sess.run(y, feed_dict = {x: test_x}) # Predict after training in the epoch\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y)) # define a function to Calculate the error of that epoch\n",
    "    mse_ = sess.run(mse)  # we run said function\n",
    "    mse_history.append(mse_)  # We append the result to a list\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y})) # Execute the accuracy function\n",
    "    accuracy_history.append(accuracy) # Append the result of the accuracy to a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teorias del error:\n",
    "    \n",
    "estamos metiendo los datos en forma de dataframe, cuando son numpy arrays realmente \n",
    "\n",
    "\n",
    " Deberíamos probar con el sistema que utilizan en el curso más aqúi \n",
    "https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errores que han surgido \n",
    "\n",
    "Cannot feed value of shape (242,) for Tensor 'Placeholder_11:0', which has shape '(242, 2)'\n",
    "\n",
    "\n",
    "Cannot feed value of shape (242,) for Tensor 'Placeholder_15:0', which has shape '(?, 1)' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
